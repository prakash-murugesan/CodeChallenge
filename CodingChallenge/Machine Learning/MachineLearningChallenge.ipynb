{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "Below are 2 data challenges that test for your ability to:\n",
    "- Wrangle/clean data to make it usable by a model\n",
    "- Figure out how to set up X's and y's for a use case, given a dataset\n",
    "- Write code to robustly and reproducibly preprocess data\n",
    "- Pick/design the right model, and tune hyperparameters to get the best performance\n",
    "\n",
    "You can use any programming language, model, and package to solve these problems. Let us know of any assumptions you make in your process.\n",
    "\n",
    "#### Deliverables:\n",
    "- A link to a github repository that contains:\n",
    "    - Clearly commented code that was written to solve these problems\n",
    "    - Your trained models stored in a file (`.pkl`, `.h5`, `.tar` - whatever is appropriate). The models must have `predict(X)` functions. \n",
    "    - A readme file that contains:\n",
    "        - Instructions to easily access/load the above\n",
    "        - A writeup explaining any significant design decisions and your reasons for making them. \n",
    "        - If needed, a brief writeup explaining anything you are particularly proud of in your implementation that you might want us to focus on\n",
    "\n",
    "#### How we'll assess your work:\n",
    "- Accuracy/RMSE of your model when predicting on held-out data\n",
    "- How well various edge cases are handled when testing on held-out data. For example, if the held-out data contains:\n",
    "    - A new column that wasn't present in the dataset given to you\n",
    "    - New value in a categorical field that wasn't seen in the dataset given to you\n",
    "    - NA values\n",
    "- Efficiency of the code. \n",
    "    - Is it easy to understand? \n",
    "    - Are the variable names descriptive? \n",
    "    - Are there any variables created that aren't used? \n",
    "    - Is redundant code replaced with function calls? \n",
    "    - Is vectorized implementation used instead of nested for loops? \n",
    "    - Are classes defined and objects created where applicable? \n",
    "    - Are packages used to perform tasks instead of implementing them from scratch?\n",
    "    \n",
    "**NOTE:** Your stored models, once loaded, should *just work* when fed with our held-out data (which looks similar to the data we've given you). We won't do any preprocessing before we feed it into the model's `predict(X)` function; `predict(X)` should handle the preprocessing. Pay particular attention to handling the edge cases we've talked about.\n",
    "\n",
    "Feel free to ask questions to clarify things. Submit everything you tried, not just the things that worked. I encourage you to try and showcase your talents. The more you go above and beyond what's expected, the more impressed we'll be. **Bonus points if you fit Keras/Tensorflow/Pytorch/Caffe models** in addition to your Linear/Tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash14\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn import preprocessing as scale\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import xgboost \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, average_precision_score, precision_score, f1_score,recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "`predictive_maintenance_dataset.csv` is a file that contains parameters and settings (`operational_setting_1`, `operational_setting_2`, `sensor_measurement_1`, `sensor_measurement_2`, etc.) for many wind turbines. There is a column called `unit_number` which specifies which turbine it is, and one called `status`, in which a value of 1 means the turbine broke down that day, and 0 means it didn't. Your task is to create a model that, when fed with operational settings and sensor measurements (`unit_number` and `time_stamp` will *not* be fed in), outputs 1 if the turbine will break down within the next 40 days, and 0 if not.\n",
    "\n",
    "**NOTE:** The model should output 1 if the turbine is anywhere between 40 and 0 days away from failure, not *only* 40 days from failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>sensor_measurement_6</th>\n",
       "      <th>sensor_measurement_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_12</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0007</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>High</td>\n",
       "      <td>445.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1362.47</td>\n",
       "      <td>1143.17</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.70</td>\n",
       "      <td>142.53</td>\n",
       "      <td>...</td>\n",
       "      <td>133.75</td>\n",
       "      <td>2388.50</td>\n",
       "      <td>8129.92</td>\n",
       "      <td>9.1182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.77</td>\n",
       "      <td>6.5717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.33</td>\n",
       "      <td>1581.03</td>\n",
       "      <td>1400.06</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.60</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.00</td>\n",
       "      <td>8135.70</td>\n",
       "      <td>8.3817</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.07</td>\n",
       "      <td>23.3958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>Low</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.71</td>\n",
       "      <td>1250.87</td>\n",
       "      <td>1037.52</td>\n",
       "      <td>7.05</td>\n",
       "      <td>9.00</td>\n",
       "      <td>174.56</td>\n",
       "      <td>...</td>\n",
       "      <td>163.11</td>\n",
       "      <td>2028.06</td>\n",
       "      <td>7867.90</td>\n",
       "      <td>10.8827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.33</td>\n",
       "      <td>8.6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>549.28</td>\n",
       "      <td>1349.42</td>\n",
       "      <td>1114.02</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.71</td>\n",
       "      <td>137.97</td>\n",
       "      <td>...</td>\n",
       "      <td>130.58</td>\n",
       "      <td>2387.71</td>\n",
       "      <td>8074.81</td>\n",
       "      <td>9.3776</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.84</td>\n",
       "      <td>1604.53</td>\n",
       "      <td>1431.41</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.30</td>\n",
       "      <td>...</td>\n",
       "      <td>519.44</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8135.95</td>\n",
       "      <td>8.5223</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38.39</td>\n",
       "      <td>23.0682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   operational_setting_1  operational_setting_2 operational_setting_3  \\\n",
       "0                42.0007                 0.8415                  High   \n",
       "1                -0.0023                 0.0004                  High   \n",
       "2                    NaN                 0.6216                   Low   \n",
       "3                42.0006                    NaN                  High   \n",
       "4                -0.0016                 0.0004                  High   \n",
       "\n",
       "   sensor_measurement_1  sensor_measurement_2  sensor_measurement_3  \\\n",
       "0                445.00                   NaN               1362.47   \n",
       "1                518.67                642.33               1581.03   \n",
       "2                462.54                536.71               1250.87   \n",
       "3                   NaN                549.28               1349.42   \n",
       "4                518.67                643.84               1604.53   \n",
       "\n",
       "   sensor_measurement_4  sensor_measurement_5  sensor_measurement_6  \\\n",
       "0               1143.17                  3.91                  5.70   \n",
       "1               1400.06                 14.62                 21.61   \n",
       "2               1037.52                  7.05                  9.00   \n",
       "3               1114.02                  3.91                  5.71   \n",
       "4               1431.41                 14.62                 21.61   \n",
       "\n",
       "   sensor_measurement_7          ...            sensor_measurement_12  \\\n",
       "0                142.53          ...                           133.75   \n",
       "1                554.60          ...                           522.19   \n",
       "2                174.56          ...                           163.11   \n",
       "3                137.97          ...                           130.58   \n",
       "4                551.30          ...                           519.44   \n",
       "\n",
       "   sensor_measurement_13  sensor_measurement_14  sensor_measurement_15  \\\n",
       "0                2388.50                8129.92                 9.1182   \n",
       "1                2388.00                8135.70                 8.3817   \n",
       "2                2028.06                7867.90                10.8827   \n",
       "3                2387.71                8074.81                 9.3776   \n",
       "4                2388.24                8135.95                 8.5223   \n",
       "\n",
       "   sensor_measurement_16  sensor_measurement_17  sensor_measurement_18  \\\n",
       "0                    NaN                  332.0                 2212.0   \n",
       "1                   0.03                  393.0                 2388.0   \n",
       "2                    NaN                  306.0                 1915.0   \n",
       "3                   0.02                    NaN                 2212.0   \n",
       "4                   0.03                  396.0                 2388.0   \n",
       "\n",
       "   sensor_measurement_19  sensor_measurement_20  sensor_measurement_21  \n",
       "0                 100.00                  10.77                 6.5717  \n",
       "1                 100.00                  39.07                23.3958  \n",
       "2                  84.93                  14.33                 8.6202  \n",
       "3                 100.00                  10.60                 6.2614  \n",
       "4                 100.00                  38.39                23.0682  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## What the data that we'll feed into your model's predict(X) function will look like:\n",
    "# Notice what the operational_setting_3 column looks like\n",
    "df_X = pd.read_csv(\"predictive_maintenance_dataset.csv\").drop(labels=['status', 'unit_number', 'time_stamp'], axis='columns')\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>status</th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_12</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73382</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-01 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.89</td>\n",
       "      <td>1583.84</td>\n",
       "      <td>1391.28</td>\n",
       "      <td>...</td>\n",
       "      <td>522.33</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8137.72</td>\n",
       "      <td>8.3905</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.94</td>\n",
       "      <td>23.4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90923</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-02 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1587.05</td>\n",
       "      <td>1393.13</td>\n",
       "      <td>...</td>\n",
       "      <td>522.70</td>\n",
       "      <td>2387.98</td>\n",
       "      <td>8131.09</td>\n",
       "      <td>8.4167</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82527</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-03 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.55</td>\n",
       "      <td>1588.32</td>\n",
       "      <td>1398.96</td>\n",
       "      <td>...</td>\n",
       "      <td>522.58</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8140.58</td>\n",
       "      <td>8.3802</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.11</td>\n",
       "      <td>23.4250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96521</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-04 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.68</td>\n",
       "      <td>1584.15</td>\n",
       "      <td>1396.08</td>\n",
       "      <td>...</td>\n",
       "      <td>522.49</td>\n",
       "      <td>2387.93</td>\n",
       "      <td>8140.44</td>\n",
       "      <td>8.4018</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>23.5027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73137</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-05 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>High</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.73</td>\n",
       "      <td>1579.03</td>\n",
       "      <td>1402.52</td>\n",
       "      <td>...</td>\n",
       "      <td>522.27</td>\n",
       "      <td>2387.94</td>\n",
       "      <td>8136.67</td>\n",
       "      <td>8.3867</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.18</td>\n",
       "      <td>23.4234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_number           time_stamp  status  operational_setting_1  \\\n",
       "73382            2  2017-04-01 12:00:00       0                -0.0018   \n",
       "90923            2  2017-04-02 12:00:00       0                 0.0043   \n",
       "82527            2  2017-04-03 12:00:00       0                 0.0018   \n",
       "96521            2  2017-04-04 12:00:00       0                 0.0035   \n",
       "73137            2  2017-04-05 12:00:00       0                 0.0005   \n",
       "\n",
       "       operational_setting_2 operational_setting_3  sensor_measurement_1  \\\n",
       "73382                 0.0006                  High                518.67   \n",
       "90923                -0.0003                  High                518.67   \n",
       "82527                 0.0003                  High                518.67   \n",
       "96521                -0.0004                  High                518.67   \n",
       "73137                 0.0004                  High                518.67   \n",
       "\n",
       "       sensor_measurement_2  sensor_measurement_3  sensor_measurement_4  \\\n",
       "73382                641.89               1583.84               1391.28   \n",
       "90923                641.82               1587.05               1393.13   \n",
       "82527                641.55               1588.32               1398.96   \n",
       "96521                641.68               1584.15               1396.08   \n",
       "73137                641.73               1579.03               1402.52   \n",
       "\n",
       "               ...            sensor_measurement_12  sensor_measurement_13  \\\n",
       "73382          ...                           522.33                2388.06   \n",
       "90923          ...                           522.70                2387.98   \n",
       "82527          ...                           522.58                2387.99   \n",
       "96521          ...                           522.49                2387.93   \n",
       "73137          ...                           522.27                2387.94   \n",
       "\n",
       "       sensor_measurement_14  sensor_measurement_15  sensor_measurement_16  \\\n",
       "73382                8137.72                 8.3905                   0.03   \n",
       "90923                8131.09                 8.4167                   0.03   \n",
       "82527                8140.58                 8.3802                   0.03   \n",
       "96521                8140.44                 8.4018                   0.03   \n",
       "73137                8136.67                 8.3867                   0.03   \n",
       "\n",
       "       sensor_measurement_17  sensor_measurement_18  sensor_measurement_19  \\\n",
       "73382                  391.0                 2388.0                  100.0   \n",
       "90923                    NaN                 2388.0                  100.0   \n",
       "82527                  391.0                 2388.0                  100.0   \n",
       "96521                  391.0                 2388.0                  100.0   \n",
       "73137                  390.0                 2388.0                  100.0   \n",
       "\n",
       "       sensor_measurement_20  sensor_measurement_21  \n",
       "73382                  38.94                23.4585  \n",
       "90923                  39.06                23.4085  \n",
       "82527                  39.11                23.4250  \n",
       "96521                  39.13                23.5027  \n",
       "73137                  39.18                23.4234  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"predictive_maintenance_dataset.csv\").sort_values(by = ['unit_number', 'time_stamp'], ascending = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(data):\n",
    "    \"\"\"\n",
    "    Function to preprocess similar datasets: \n",
    "    Takes in a dataframe, checks for null values, replaces categorical value columns with dummy variables\n",
    "    and fills the remaining null values in the numerical columns with the means of that column\"\"\"\n",
    "    \n",
    "    df = data\n",
    "    df.fillna(method='ffill', inplace=True)         #As the data is arranged chronologically, we fill the next missing variable with that of the previous hour/day\n",
    "    df.fillna(method='bfill', inplace=True)         #Incase some NaNs are at the start\n",
    "    \n",
    "    categorical_columns = df.select_dtypes(include=['object'])\n",
    "    dummy_columns = pd.get_dummies(categorical_columns)\n",
    "    \n",
    "    df = pd.concat([df.drop(categorical_columns, axis=1), dummy_columns], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an interesting case here: where we're checking if a turbine is going to fail in 40 days or less. So essentially we're trying to figure out a problem where given all the parameters what is the likelihood that a certain unit fails within a 40 day timespan. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just have to identify the date the turbines failed and mark the data going back up to a maximum of 40 days as a failure as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLabels(df,y_col, limit=40):\n",
    "    \"\"\"\n",
    "    Function that takes in the dataframe, the target-variable column, and a number defining the window period for failure. \n",
    "    Returns a dataframe with the required target variable\n",
    "    \"\"\"\n",
    "     \n",
    "    y_col_new = y_col + '_new'\n",
    "    df[y_col_new] = df[y_col]\n",
    "    df[y_col_new] = df[y_col_new].replace(0, np.NaN) #Let's replace all the 0s with NaNs and then we work backwords\n",
    "    df[y_col_new] = df[y_col_new].fillna(method='bfill', limit=40) # fill backward up to 40days. Thankfully the data is frequent and daily\n",
    "    df[y_col_new] = df[y_col_new].fillna('0') #fill the rest with zeros\n",
    "    df.drop(y_col, axis = 1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \"\"\"\n",
    "    Function that takes in a dataset with numerical values and standardizes it\n",
    "    \"\"\"\n",
    "    standard_sc = scale.StandardScaler()\n",
    "    x_std = standard_sc.fit_transform(df)\n",
    "    df_scaled = pd.DataFrame(x_std)\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(df_X, y, dtype, test_size=0.2):\n",
    "    \"\"\"Function to split the training data into training, validation, and testing size and convert target variable to required type\"\"\"\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_X, y, test_size = test_size, random_state = 19)\n",
    "    #xtrain, xval, ytrain, yval = train_test_split(df_X, y, test_size = valid_size, random_state = 19)\n",
    "    \n",
    "    ytrain, ytest = ytrain.astype(dtype), ytest.astype(dtype)\n",
    "    return xtrain, xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ytest, pred):\n",
    "    \"\"\"\n",
    "    Function to evaluate models against models \n",
    "    \"\"\"\n",
    "    print('accuracy score: ', accuracy_score(ytest, pred))\n",
    "    print('Recall score: ', recall_score(ytest,pred))\n",
    "    \n",
    "    print('Precision Score: ',precision_score(ytest,pred))\n",
    "    print('F1_score: ',f1_score(ytest, pred))\n",
    "    print('roc_auc_score: ', roc_auc_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(training_model):\n",
    "    \"\"\"\n",
    "    Function to receive training model and perform and evaluate predictions\n",
    "    \"\"\"\n",
    "    model = training_model.fit(xtrain.values,ytrain.values)\n",
    "    pred = model.predict(xtest.values)\n",
    "    metrics(pred,ytest)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(xtrain,xtest,ytrain,ytest):\n",
    "    LR = LogisticRegression(multi_class='ovr')\n",
    "    pred = score(LR)\n",
    "    return pred\n",
    "\n",
    "def randomForestClassifier(xtrain,xtest,ytrain,ytest,n_estimators=25,min_samples_split=25,max_depth=5,random_state=72):\n",
    "    RF = RandomForestClassifier(n_estimators = 50, min_samples_split=25, max_depth =10, random_state=72)\n",
    "    pred = score(RF)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(dataset):\n",
    "    return pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDrop(dataset, first_column, second_column):\n",
    "    \"\"\"Function that sorts by first and second column and drops those columns after..very specific..I know\"\"\"\n",
    "    return dataset.sort_values(by = [first_column, second_column]).drop([first_column,second_column],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbClassifier(xtrain,xval,ytrain,yval):\n",
    "    xgb = xgboost.XGBClassifier( max_depth=20, n_estimators=200, learning_rate=0.05, objective='binary:logistic')\n",
    "    model = xgb.fit(xtrain,ytrain)\n",
    "    pred = xgb.predict(xval)\n",
    "    metrics(yval, pred)\n",
    "    \n",
    "    #pickle.dump(model, open(\"xbg_model.pkl\",\"wb\")) \n",
    "    joblib.dump(xgb, \"xgbmodel\")\n",
    "    print (\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "    \"\"\"\n",
    "    Function that receives the filename as a string, reads the data, preprocesses, splits, and trains with an XGB Classifier\n",
    "    which then saves the model\"\"\"\n",
    "    \n",
    "    df = readData(dataset)\n",
    "    \n",
    "    df = sortDrop(df, 'unit_number', 'time_stamp')\n",
    "    \n",
    "    df = preProcess(df)\n",
    "    \n",
    "    df = setLabels(df, 'status', 40)\n",
    "    \n",
    "    df_y = df['status_new']\n",
    "    df_X = df.drop('status_new', axis = 1)\n",
    "    \n",
    "    df_X = normalize(df_X)\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = dataSplit(df_X, df_y, int, test_size=0.25)\n",
    "    \n",
    "    xgbClassifier(xtrain,xtest,ytrain,ytest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9476574852292585\n",
      "Recall score:  0.8214613268113726\n",
      "Precision Score:  0.8819957328081405\n",
      "F1_score:  0.8506529481598734\n",
      "roc_auc_score:  0.8985479394909484\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash14\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "train(\"predictive_maintenance_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(dataset):\n",
    "    \n",
    "    \n",
    "    #df = readData(dataset)\n",
    "    df = preProcess(dataset)\n",
    "    \n",
    "    df = normalize(df)\n",
    "    \n",
    "    loaded_model = joblib.load(\"xgbmodel\")\n",
    "    \n",
    "    y_pred = loaded_model.predict(df)\n",
    "    \n",
    "    #metrics(ytest,y_pred)\n",
    "    print(y_pred)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "`forecasting_dataset.csv` is a file that contains pollution data for a city. Your task is to create a model that, when fed with columns `co_gt`, `nhmc`, `c6h6`, `s2`, `nox`, `s3`, `no2`, `s4`, `s5`, `t`, `rh`, `ah`, and `level`, predicts the value of `y` six hours later.\n",
    "\n",
    "**NOTE:** In the data we've given you, the value of `y` for a given row is the value of `y` *for the timestamp of that same row*. We're asking you to predict the value of `y` 6 hours *after the timestamp of that row*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>578.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>968.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.6394</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>626.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1.4519</td>\n",
       "      <td>Very low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>1.6</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>832.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      co_gt   nhmc  c6h6      s2    nox      s3    no2      s4      s5     t  \\\n",
       "8416 -200.0 -200.0   1.9   578.0 -200.0  1017.0 -200.0   876.0   607.0   5.8   \n",
       "8417    1.3 -200.0   9.7   968.0  115.0  1276.0  112.0  1325.0   768.0  31.8   \n",
       "8418    NaN   54.0   2.6   626.0   39.0  1325.0   52.0  1284.0   755.0   9.6   \n",
       "8419 -200.0 -200.0  21.0  1324.0 -200.0   527.0 -200.0  1886.0  1571.0  22.9   \n",
       "8420    1.6 -200.0   6.4   832.0  244.0   748.0  119.0  1230.0   934.0   NaN   \n",
       "\n",
       "        rh      ah     level  \n",
       "8416  59.0  0.5493  Very low  \n",
       "8417  13.8  0.6394      High  \n",
       "8418  58.5  0.7000       Low  \n",
       "8419  52.6  1.4519  Very low  \n",
       "8420  59.9  0.9261      High  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## What the data that we'll feed into your model's predict(X) function will look like:\n",
    "# Notice what the level column looks like\n",
    "A = pd.read_csv(\"forecasting_dataset.csv\").drop(labels=['date', 'time', 'y'], axis='columns')\n",
    "A.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readData2(data):\n",
    "    data = pd.read_csv(\"forecasting_dataset.csv\", parse_dates=[['date','time']]).sort_values(by = ['date_time'])\n",
    "    data.drop('date_time', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLabels2(df):\n",
    "    \"\"\"\n",
    "    Function that converts the time series to a supervised learning problem by shifting the time labels by 6 hours\n",
    "    \"\"\"\n",
    "    df['y_6_hours_later'] = df.y.shift(-6)\n",
    "    df.drop('y', axis=1, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXandY(df):\n",
    "    \"\"\"\n",
    "    Function that splits the dataset into training examples and labels\n",
    "    \"\"\"\n",
    "    df_X = df.iloc[:,:-1]\n",
    "    df_y = df.iloc[:,-1:]\n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestRegression(xtrain,xtest, ytrain, ytest):\n",
    "    RFR = RandomForestRegressor(max_depth = 25,random_state = 9, n_estimators = 210, min_samples_split = 2,min_samples_leaf =1)\n",
    "    \n",
    "    model = RFR.fit(xtrain,ytrain)\n",
    "    pred = model.predict(xtest)\n",
    "    \n",
    "    R2score = RFR.score(xtest, ytest)    \n",
    "    print(\"R2 score\",(R2score))\n",
    "    print(sqrt(mean_squared_error(ytest,pred)))\n",
    "    \n",
    "    joblib.dump(model, \"RandomForestRegressormodel\")\n",
    "    print (\"model saved\")\n",
    "    \n",
    "    #metrics(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "    \n",
    "    df = readData2(dataset)\n",
    "    df = preProcess(df)\n",
    "    df = setLabels2(df)\n",
    "    \n",
    "    df_X, df_y = generateXandY(df)\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = dataSplit(df_X, df_y, float, test_size=0.25)\n",
    "    \n",
    "    randomForestRegression(xtrain, xtest, ytrain, ytest)    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash14\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\ipykernel\\__main__.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.5902549350238033\n",
      "221.45892805223028\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "train(\"forecasting_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset):    \n",
    "    \n",
    "    df = preProcess(dataset)\n",
    "    \n",
    "    #df = normalize(df)\n",
    "    \n",
    "    #loaded_model = pickle.load(open(\"xgb_model.pkl\", \"rb\"))\n",
    "    loaded_model = joblib.load(\"RandomForestRegressormodel\")\n",
    "    \n",
    "    y_pred = loaded_model.predict(df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 893.56571429, 1209.14214286,  819.57142857, ..., 1196.71142857,\n",
       "       1230.38857143, 1103.31857143])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
