{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "Below are 2 data challenges that test for your ability to:\n",
    "- Wrangle/clean data to make it usable by a model\n",
    "- Figure out how to set up X's and y's for a use case, given a dataset\n",
    "- Write code to robustly and reproducibly preprocess data\n",
    "- Pick/design the right model, and tune hyperparameters to get the best performance\n",
    "\n",
    "You can use any programming language, model, and package to solve these problems. Let us know of any assumptions you make in your process.\n",
    "\n",
    "#### Deliverables:\n",
    "- A link to a github repository that contains:\n",
    "    - Clearly commented code that was written to solve these problems\n",
    "    - Your trained models stored in a file (`.pkl`, `.h5`, `.tar` - whatever is appropriate). The models must have `predict(X)` functions. \n",
    "    - A readme file that contains:\n",
    "        - Instructions to easily access/load the above\n",
    "        - A writeup explaining any significant design decisions and your reasons for making them. \n",
    "        - If needed, a brief writeup explaining anything you are particularly proud of in your implementation that you might want us to focus on\n",
    "\n",
    "#### How we'll assess your work:\n",
    "- Accuracy/RMSE of your model when predicting on held-out data\n",
    "- How well various edge cases are handled when testing on held-out data. For example, if the held-out data contains:\n",
    "    - A new column that wasn't present in the dataset given to you\n",
    "    - New value in a categorical field that wasn't seen in the dataset given to you\n",
    "    - NA values\n",
    "- Efficiency of the code. \n",
    "    - Is it easy to understand? \n",
    "    - Are the variable names descriptive? \n",
    "    - Are there any variables created that aren't used? \n",
    "    - Is redundant code replaced with function calls? \n",
    "    - Is vectorized implementation used instead of nested for loops? \n",
    "    - Are classes defined and objects created where applicable? \n",
    "    - Are packages used to perform tasks instead of implementing them from scratch?\n",
    "    \n",
    "**NOTE:** Your stored models, once loaded, should *just work* when fed with our held-out data (which looks similar to the data we've given you). We won't do any preprocessing before we feed it into the model's `predict(X)` function; `predict(X)` should handle the preprocessing. Pay particular attention to handling the edge cases we've talked about.\n",
    "\n",
    "Feel free to ask questions to clarify things. Submit everything you tried, not just the things that worked. I encourage you to try and showcase your talents. The more you go above and beyond what's expected, the more impressed we'll be. **Bonus points if you fit Keras/Tensorflow/Pytorch/Caffe models** in addition to your Linear/Tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import preprocessing as scale\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(df):\n",
    "    \"\"\"\n",
    "    Function to preprocess similar datasets: \n",
    "    Takes in a dataframe, checks for null values, replaces categorical value columns with dummy variables\n",
    "    and fills the remaining null values in the numerical columns with the means of that column\"\"\"\n",
    "    \n",
    "    df.fillna(method='ffill', inplace=True)         #As the data is arranged chronologically, we fill the next missing variable with that of the previous hour/day\n",
    "    df.fillna(method='bfill', inplace=True)         #Incase some NaNs are at the start\n",
    "    \n",
    "    categorical_columns = df.select_dtypes(include=['object'])\n",
    "    dummy_columns = pd.get_dummies(categorical_columns)\n",
    "    \n",
    "    df = pd.concat([df.drop(categorical_columns, axis=1), dummy_columns], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(df_X, y, dtype, test_size=0.2):\n",
    "    \"\"\"Function to split the training data into training, validation, and testing size and convert target variable to required type\"\"\"\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_X, y, test_size = test_size, random_state = 19)\n",
    "    \n",
    "    ytrain, ytest = ytrain.astype(dtype), ytest.astype(dtype)\n",
    "    return xtrain, xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "`forecasting_dataset.csv` is a file that contains pollution data for a city. Your task is to create a model that, when fed with columns `co_gt`, `nhmc`, `c6h6`, `s2`, `nox`, `s3`, `no2`, `s4`, `s5`, `t`, `rh`, `ah`, and `level`, predicts the value of `y` six hours later.\n",
    "\n",
    "**NOTE:** In the data we've given you, the value of `y` for a given row is the value of `y` *for the timestamp of that same row*. We're asking you to predict the value of `y` 6 hours *after the timestamp of that row*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we follow the same process to prep the data as the last two notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>nhmc</th>\n",
       "      <th>c6h6</th>\n",
       "      <th>s2</th>\n",
       "      <th>nox</th>\n",
       "      <th>s3</th>\n",
       "      <th>no2</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>t</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>867.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>704.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.9612</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.7</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1.0919</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.0479</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>54.1</td>\n",
       "      <td>0.8003</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   co_gt   nhmc  c6h6      s2    nox     s3    no2      s4      s5     t  \\\n",
       "0 -200.0 -200.0   7.2   867.0 -200.0  834.0 -200.0  1314.0   891.0  14.8   \n",
       "1    0.5 -200.0   3.9   704.0 -200.0  861.0 -200.0  1603.0   860.0  24.4   \n",
       "2    3.7 -200.0  23.3  1386.0    NaN  626.0  109.0  2138.0     NaN  23.3   \n",
       "3    2.1 -200.0  12.1  1052.0  183.0  779.0    NaN  1690.0   952.0  28.5   \n",
       "4    4.4 -200.0  21.7  1342.0  786.0  499.0  206.0  1546.0  2006.0  12.9   \n",
       "\n",
       "     rh      ah level  \n",
       "0  57.3  0.9603   NaN  \n",
       "1  65.0  1.9612   Low  \n",
       "2  38.6  1.0919  High  \n",
       "3  27.3  1.0479  High  \n",
       "4  54.1  0.8003  High  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## What the data that we'll feed into your model's predict(X) function will look like:\n",
    "# Notice what the level column looks like\n",
    "pd.read_csv(\"forecasting_dataset.csv\").drop(labels=['date', 'time', 'y'], axis='columns').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"forecasting_dataset.csv\", parse_dates=[['date','time']]).sort_values(by = ['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = preProcess(df.drop(['date_time'], axis =1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['y_6_hours_later'] = df.y.shift(-6)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMS in Keras, however, don't accept pandas dataframes unfortunately. So we move our data over to numpy arrays to perform scaling and transformations.\n",
    "The MinMax scaler is later recalled after the model is fit, to transform the data back up for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.drop('y', axis=1).values\n",
    "MinMax = scale.MinMaxScaler(feature_range=[-1,1])\n",
    "scaled_data = MinMax.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91222275, -0.49604032,  0.60712931, ..., -1.        ,\n",
       "        -1.        ,  0.23660714],\n",
       "       [ 0.9065597 , -0.55075594,  0.58816837, ..., -1.        ,\n",
       "        -1.        ,  0.19285714],\n",
       "       [ 0.90844738, -0.58531317,  0.58513462, ..., -1.        ,\n",
       "        -1.        ,  0.15535714],\n",
       "       ...,\n",
       "       [ 0.8952336 , -1.        ,  0.53962837, ..., -1.        ,\n",
       "        -1.        ,  0.125     ],\n",
       "       [ 0.90184049, -1.        ,  0.55858931, ..., -1.        ,\n",
       "        -1.        ,  0.17946429],\n",
       "       [ 0.91694195, -1.        ,  0.61471369, ..., -1.        ,\n",
       "        -1.        ,  0.17678571]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into X and y variables. The transformed column being the one appended the last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data[:,:17]\n",
    "y = scaled_data[:,17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8415, 18)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have such few training samples we must make sure that our model doesn't overfit the data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = dataSplit(X, y, float, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5890, 17)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMS are picky data eaters. So we must transform the data shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5890, 1, 17) (5890, 1) (2525, 1, 17) (2525, 1)\n"
     ]
    }
   ],
   "source": [
    "xtrain = xtrain.reshape((xtrain.shape[0],1,xtrain.shape[1]))\n",
    "xtest = xtest.reshape((xtest.shape[0],1,xtest.shape[1]))\n",
    "print(xtrain.shape, ytrain.shape, xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb is to set the LSTM size between the number of output params and the number of input variables. In our case we have 17 variables with an output of 1. So we can pick a midpoint of 10! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape = (xtrain.shape[1],xtrain.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_9 (LSTM)                    (None, 10)            1120        lstm_input_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             11          lstm_9[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1,131\n",
      "Trainable params: 1,131\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5890 samples, validate on 2525 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.1492 - val_loss: 0.0914\n",
      "Epoch 2/50\n",
      "0s - loss: 0.0763 - val_loss: 0.0707\n",
      "Epoch 3/50\n",
      "0s - loss: 0.0621 - val_loss: 0.0625\n",
      "Epoch 4/50\n",
      "0s - loss: 0.0568 - val_loss: 0.0596\n",
      "Epoch 5/50\n",
      "0s - loss: 0.0549 - val_loss: 0.0585\n",
      "Epoch 6/50\n",
      "0s - loss: 0.0540 - val_loss: 0.0578\n",
      "Epoch 7/50\n",
      "0s - loss: 0.0534 - val_loss: 0.0572\n",
      "Epoch 8/50\n",
      "0s - loss: 0.0530 - val_loss: 0.0568\n",
      "Epoch 9/50\n",
      "0s - loss: 0.0526 - val_loss: 0.0565\n",
      "Epoch 10/50\n",
      "0s - loss: 0.0523 - val_loss: 0.0562\n",
      "Epoch 11/50\n",
      "0s - loss: 0.0521 - val_loss: 0.0560\n",
      "Epoch 12/50\n",
      "0s - loss: 0.0519 - val_loss: 0.0558\n",
      "Epoch 13/50\n",
      "0s - loss: 0.0518 - val_loss: 0.0556\n",
      "Epoch 14/50\n",
      "0s - loss: 0.0516 - val_loss: 0.0555\n",
      "Epoch 15/50\n",
      "0s - loss: 0.0515 - val_loss: 0.0553\n",
      "Epoch 16/50\n",
      "0s - loss: 0.0514 - val_loss: 0.0552\n",
      "Epoch 17/50\n",
      "0s - loss: 0.0513 - val_loss: 0.0551\n",
      "Epoch 18/50\n",
      "0s - loss: 0.0512 - val_loss: 0.0550\n",
      "Epoch 19/50\n",
      "0s - loss: 0.0511 - val_loss: 0.0549\n",
      "Epoch 20/50\n",
      "0s - loss: 0.0510 - val_loss: 0.0549\n",
      "Epoch 21/50\n",
      "0s - loss: 0.0509 - val_loss: 0.0548\n",
      "Epoch 22/50\n",
      "0s - loss: 0.0509 - val_loss: 0.0547\n",
      "Epoch 23/50\n",
      "0s - loss: 0.0508 - val_loss: 0.0547\n",
      "Epoch 24/50\n",
      "0s - loss: 0.0508 - val_loss: 0.0546\n",
      "Epoch 25/50\n",
      "0s - loss: 0.0507 - val_loss: 0.0546\n",
      "Epoch 26/50\n",
      "0s - loss: 0.0507 - val_loss: 0.0545\n",
      "Epoch 27/50\n",
      "0s - loss: 0.0506 - val_loss: 0.0545\n",
      "Epoch 28/50\n",
      "0s - loss: 0.0506 - val_loss: 0.0544\n",
      "Epoch 29/50\n",
      "0s - loss: 0.0505 - val_loss: 0.0544\n",
      "Epoch 30/50\n",
      "0s - loss: 0.0505 - val_loss: 0.0544\n",
      "Epoch 31/50\n",
      "0s - loss: 0.0504 - val_loss: 0.0543\n",
      "Epoch 32/50\n",
      "0s - loss: 0.0504 - val_loss: 0.0543\n",
      "Epoch 33/50\n",
      "0s - loss: 0.0504 - val_loss: 0.0543\n",
      "Epoch 34/50\n",
      "0s - loss: 0.0503 - val_loss: 0.0542\n",
      "Epoch 35/50\n",
      "0s - loss: 0.0503 - val_loss: 0.0542\n",
      "Epoch 36/50\n",
      "0s - loss: 0.0503 - val_loss: 0.0542\n",
      "Epoch 37/50\n",
      "0s - loss: 0.0502 - val_loss: 0.0541\n",
      "Epoch 38/50\n",
      "0s - loss: 0.0502 - val_loss: 0.0541\n",
      "Epoch 39/50\n",
      "0s - loss: 0.0502 - val_loss: 0.0541\n",
      "Epoch 40/50\n",
      "0s - loss: 0.0501 - val_loss: 0.0541\n",
      "Epoch 41/50\n",
      "0s - loss: 0.0501 - val_loss: 0.0540\n",
      "Epoch 42/50\n",
      "0s - loss: 0.0501 - val_loss: 0.0540\n",
      "Epoch 43/50\n",
      "0s - loss: 0.0501 - val_loss: 0.0540\n",
      "Epoch 44/50\n",
      "0s - loss: 0.0500 - val_loss: 0.0540\n",
      "Epoch 45/50\n",
      "0s - loss: 0.0500 - val_loss: 0.0539\n",
      "Epoch 46/50\n",
      "0s - loss: 0.0500 - val_loss: 0.0539\n",
      "Epoch 47/50\n",
      "0s - loss: 0.0500 - val_loss: 0.0539\n",
      "Epoch 48/50\n",
      "0s - loss: 0.0499 - val_loss: 0.0539\n",
      "Epoch 49/50\n",
      "0s - loss: 0.0499 - val_loss: 0.0539\n",
      "Epoch 50/50\n",
      "0s - loss: 0.0499 - val_loss: 0.0538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f2e66bb160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit\n",
    "history = model.fit(xtrain, ytrain, nb_epoch=50, batch_size=128, validation_data=(xtest,ytest), verbose=2, shuffle=False)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape our variables to shapes we're more familiar with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xtest)\n",
    "xtest = xtest.reshape((xtest.shape[0], xtest.shape[2])) #reshaping it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2525, 17)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to go back to our scaling model to expand our arrays back up to check the rmse. \n",
    "\n",
    "When we first scaled the dataset, the X and y variables were together so we must join them back up when we inverse scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525,)\n"
     ]
    }
   ],
   "source": [
    "#inver scaling to forecast\n",
    "y_pred_inv = concatenate((xtest,y_pred), axis=1)\n",
    "\n",
    "y_pred_inv = MinMax.inverse_transform(y_pred_inv)\n",
    "y_pred_inv = y_pred_inv[:,-1]\n",
    "print(y_pred_inv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process is repeated for our test variable. It is added back and scaled up and separated again to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525,)\n"
     ]
    }
   ],
   "source": [
    "#inver scaling for truth value\n",
    "ytest = ytest.reshape((len(ytest),1))\n",
    "y_inv = concatenate((xtest,ytest), axis=1)\n",
    "y_inv = MinMax.inverse_transform(y_inv)\n",
    "y_inv = y_inv[:,-1]\n",
    "print(y_inv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1071.15481138, 1314.26640034, 1053.85673523, ..., 1065.87261438,\n",
       "       1003.56307745, 1130.34979105])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 834., 1453.,  843., ...,  726., -200., 1349.])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(y_inv, y_pred_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.88046579380625"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM has a worse performance in the end! We can just keep this separate as it was fun and insightful to compare. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
